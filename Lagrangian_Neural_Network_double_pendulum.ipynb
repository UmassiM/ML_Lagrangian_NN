{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modellatore/Codes/blob/main/Umassi_LNN_double_pendulum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "id": "F4pFTn0XBhes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from functools import partial\n",
        "from torch.autograd.functional import jacobian, hessian\n",
        "from torchdiffeq import odeint as tor_odeint"
      ],
      "metadata": {
        "id": "NQLang2XBj68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def E(x, g=9.81, m1=1, m2=1, l1=1, l2=1):\n",
        "    try:\n",
        "        q, qt = torch.split(x, 2)\n",
        "        cos = torch.cos\n",
        "    except: \n",
        "        q, qt = np.split(x, 2)\n",
        "        cos = np.cos\n",
        "    t1, t2 = q[0], q[1]     #theta 1 and 2\n",
        "    tt1, tt2 = qt[0], qt[1] #time derivatives of t1 and t2\n",
        "\n",
        "    T = 0.5*m1*l1**2* tt1**2 * 0.5*m2*((l1*tt1)**2 + (l2*tt2)**2+2*l1*l2* tt1*tt2 *cos(t1-t2))\n",
        "    V = -(m1+m2)*g*l1* cos(t1) - m2*g*l2* cos(t2)\n",
        "    return T + V\n",
        "\n",
        "def get_qdtt(q, qt, g=9.81, m1=1, m2=1, l1=1, l2=1):                                                #given generalized coord & vel it gives back accelerations\n",
        "\n",
        "    qdtt = np.zeros_like(q)\n",
        "    cos = np.cos\n",
        "    sin = np.sin\n",
        "    \n",
        "    t1, t2 = q[:,0], q[:,1]       #theta 1 and 2\n",
        "    tt1, tt2 = qt[:,0], qt[:,1]   #velocities of t1 and t2\n",
        "    \n",
        "    a = -g*(2*m1+m2)*sin(t1) - m2*g*sin(t1-2*t2) -2*m2*sin(t1-t2) * (l2*tt2**2 + l1*tt1**2*cos(t1-t2)) \n",
        "    b = l1 * (2*m1+m2-m2*cos(2*t1-2*t2))\n",
        "    qdtt[:, 0] =  a / b  # acceleration of theta1 \n",
        "    \n",
        "    c = 2*sin(t1-t2) * (l1*tt1**2*(m1+m2) + g*(m1+m2)*cos(t1) + l2*m2*tt2**2*cos(t1-t2))\n",
        "    qdtt[:, 1] = c / b   # acceleration of theta2\n",
        "\n",
        "    return qdtt  \n",
        "\n",
        "def get_xt_anal(x, t):\n",
        "    d = np.zeros_like(x)\n",
        "    d[:, :2] = x[:, 2:]                           #take last 2 coloumns of x and put them in the first 2 of d (so qt)\n",
        "    d[:, 2:] = get_qdtt(x[:, :2], x[:, 2:])       #compute the accelerations (from q, qt)\n",
        "    return d                                      # d = qt (input), qtt analytical\n",
        "\n",
        "def anal_solve_ode(q0, qt0, t,):\n",
        "\n",
        "    x0 = np.append(q0, qt0)\n",
        "\n",
        "    def f_anal(x, t):\n",
        "        d = np.zeros_like(x)\n",
        "        d[:2] = x[2:]                                                                    #qt same as input\n",
        "        d[2:] = np.squeeze(get_qdtt(np.expand_dims(x[:2], axis=0), np.expand_dims(x[2:], axis=0))) #qtt analytical\n",
        "        return d \n",
        "    return odeint(f_anal, x0, t)                                  #integrate for q, qt\n",
        "    \n",
        "def q2xy(ql, l1=1, l2=1):         #from q, qt to cartesian coordinates and velocities \n",
        "    \n",
        "    try: \n",
        "        xy = np.zeros_like(ql)\n",
        "        sin = np.sin\n",
        "        cos = np.cos\n",
        "    except: \n",
        "        xy = torch.zeros_like(ql)\n",
        "        sin = torch.sin\n",
        "        cos = torch.cos\n",
        "        \n",
        "    t1, t2 = ql[:,0], ql[:,1]     #theta 1 and 2\n",
        "    tt1, tt2 = ql[:,2], ql[:,3]  #time derivatives of t1 and t2\n",
        "\n",
        "    xy[:, 0] = l1*sin(t1) + l2*sin(t2)                       #x\n",
        "    xy[:, 1] = l1*cos(t1) + l2*cos(t2)                       #y\n",
        "    xy[:, 2] = l1*tt1*cos(t1) + l2*tt2*cos(t2)               #vx\n",
        "    xy[:, 3] = l1*tt1*sin(t1) + l2*tt2*sin(t2)               #vy\n",
        "    return xy\n"
      ],
      "metadata": {
        "id": "TMSUlzOfBlek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### M O D E L ####################################################\n",
        "\n",
        "class LNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)\n",
        "        self.sp = nn.Softplus(beta=1)   #beta = 1 is steeper, so derivative = 1 is approached faster \n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def lagrangian(self, x): \n",
        "        x = self.sp(self.fc1(x))\n",
        "        x = self.sp(self.fc2(x))\n",
        "        x = self.sp(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x   \n",
        "    \n",
        "    def _init_weights(self, module):\n",
        "      if isinstance(module, nn.Linear):                     #normalize weights according to paper\n",
        "          self.fc1.weight.data.normal_(mean=0.0, std=2.2/4)  #1st layer is 2.2/sqrt(n_1)\n",
        "          self.fc2.weight.data.normal_(mean=0.0, std=0.58/4) #i-th layer is 0.58i/sqrt(n_i)\n",
        "          self.fc3.weight.data.normal_(mean=0.0, std=0.58*2/4)\n",
        "          self.fc4.weight.data.normal_(mean=0.0, std=4)    #last layer is sqrt(n)\n",
        "          self.fc1.bias.data.zero_()\n",
        "          self.fc2.bias.data.zero_()\n",
        "          self.fc3.bias.data.zero_()\n",
        "          self.fc4.bias.data.zero_()\n",
        "    \n",
        "    def forward(self, x):  #   r, th, rt, tht \n",
        "        n = x.shape[1]//2  #   2   \n",
        "        xv = torch.autograd.Variable(x, requires_grad=True)                  \n",
        "        xv_tup = tuple([xi for xi in x]) \n",
        "        tqt = xv[:, n:]   #   rt, tht  \n",
        "\n",
        "        jacpar = partial(jacobian,  self.lagrangian, create_graph=True)\n",
        "        hesspar = partial(hessian,  self.lagrangian, create_graph=True)\n",
        "      \n",
        "        A = tuple(map(hesspar, xv_tup))    #   \n",
        "        B = tuple(map(jacpar, xv_tup))\n",
        "        #                                                 dqt dqt         dq          dqt dq  @ qt\n",
        "        #                                                 [2:, 2:]       [:2, 0]     [2:, :2] @ rt, tht        \n",
        "        multi = lambda Ai, Bi, tqti, n:  torch.pinverse(Ai[n:, n:]) @ (Bi[:n, 0] - Ai[n:, :n] @ tqti) \n",
        "        multi_par = partial(multi, n=n)\n",
        "        tqtt_tup = tuple(map(multi_par, A, B, tqt))\n",
        "        tqtt = torch.cat([tqtti[None] for tqtti in tqtt_tup])\n",
        "\n",
        "        xt = torch.cat([tqt, tqtt], axis=1)\n",
        "        xt.retain_grad()\n",
        "        return xt                        #qt (same as input), qtt \n",
        "\n",
        "    def t_forward(self, t, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "tr_params = sum(p.numel() for p in LNN().parameters() if p.requires_grad)\n",
        "print('Trainable parameters= %i' %tr_params)\n",
        "\n",
        "def loss(pred, targ):\n",
        "    return torch.mean((pred - targ)**2)\n",
        "\n",
        "def nn_solve_ode(model, x0, t):\n",
        "\n",
        "    x0 = x0.detach().numpy()\n",
        "    def f(x, t):\n",
        "        x_tor = torch.tensor(np.expand_dims(x, 0), requires_grad=True).float()\n",
        "        return np.squeeze(model(x_tor).detach().numpy(), axis=0)\n",
        "    return odeint(f, x0, t)\n"
      ],
      "metadata": {
        "id": "8KJ1zLKxBlhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################ P A R A M E T E R S #############################################################\n",
        "\n",
        "eps = 200           #epochs\n",
        "t = 3              #duration of motion\n",
        "tl = 4             #length of samples\n",
        "N = tl              #len of training sample (if shorter, less motion)\n",
        "\n",
        "samples = 512        #samples to train on\n",
        "batches = [2]      #different batch sizes for training\n",
        "lrs = [1e-3]        #different learning rates for optimizer\n",
        "\n",
        "#StepLR decays the learn rate\n",
        "ef, gm = 10 , 0.5  #every st epochs, lr= lr*gm, so lr_final= lr* gm^ef\n",
        "st = eps//ef\n",
        "\n",
        "b_len, lr_len = len(batches), len(lrs)\n",
        "print('Sample size= %i' %int(samples*tl))"
      ],
      "metadata": {
        "id": "ru_W4NGjBljg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################# T R A I N # S E T # A N D # P L O T S ##########################################\n",
        "\n",
        "t_train = torch.tensor(np.linspace(0, t, tl)).float()\n",
        "ini_cond = torch.rand(samples, 4)  #randomized initial conditions\n",
        "\n",
        "x_train = torch.empty((0, 4))\n",
        "xt_train = torch.empty((0, 4))\n",
        "\n",
        "for x0 in ini_cond:\n",
        "    x = torch.tensor(anal_solve_ode(x0[:2], x0[2:], t_train)) #q, qt analytical\n",
        "    xt = torch.tensor(get_xt_anal(x, t_train)).float()    #qt, qtt anal \n",
        "\n",
        "    x_train = torch.cat((x_train, x))    #chain it all   \n",
        "    xt_train = torch.cat((xt_train, xt))         \n",
        "\n",
        "    \n",
        "ind = torch.randperm(x_train.shape[0])\n",
        "x_train = x_train[ind, :]     #shuffle\n",
        "xt_train = xt_train[ind, :]"
      ],
      "metadata": {
        "id": "HoE3EhONBll_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################# T R A I N I N G #################################################################\n",
        "\n",
        "model = [LNN()]*len(batches)\n",
        "model = np.expand_dims(model, 1)\n",
        "a = model\n",
        "for i in range(lr_len-1):\n",
        "    model = np.concatenate((model,a),axis=1)   #model is now a matrix containing LNN() in all entries\n",
        "                                               #model[i,j] is then trained with i-th batch size and j-th learning rate\n",
        "\n",
        "loss_list = np.zeros((b_len, lr_len,eps))\n",
        "times = []\n",
        "\n",
        "loss_list = np.zeros((b_len, lr_len,eps))\n",
        "times = []\n",
        "\n",
        "for i in range(b_len):\n",
        "    start = time.time()\n",
        "    \n",
        "    for j in range(lr_len):\n",
        "        #optimizer = optim.SGD(model[i,j].parameters(), lr=lrs[j], momentum=0.9)\n",
        "        optimizer = optim.Adam(model[i,j].parameters(), lr=lrs[j])\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=st, gamma=gm)  #decaying learn rate\n",
        "\n",
        "        for e in range(eps):\n",
        "            running_loss = 0.\n",
        "\n",
        "            for k in range((tl*samples) // batches[i]):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                xi = x_train[k*batches[i]:(k+1)*batches[i]]\n",
        "                xti = xt_train[k*batches[i]:(k+1)*batches[i]]   #qt, qtt 4 comp\n",
        "                \n",
        "                xt_pred = model[i,j](xi.float())      #qt, qtt\n",
        "                loss_val = loss(xt_pred[:,2:], xti[:,2:])\n",
        "                loss_val.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss_val.item()\n",
        "                    \n",
        "            loss_list[i,j,e] = running_loss / N / samples \n",
        "            scheduler.step()\n",
        "            running_loss = 0.0\n",
        "\n",
        "    end = time.time()\n",
        "    times.append((end-start) / lr_len)"
      ],
      "metadata": {
        "id": "N4280buwBlos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################ S A V I N G ########################################################\n",
        "\n",
        "r = int(time.time() % 10000)\n",
        "nmod = b_len * lr_len\n",
        "\n",
        "np.save('DP2 %i' %r, model)\n",
        "#model= np.load('9 models 9545.npy', allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "g-rdfCuqBlrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################### T E S T ##########################################################\n",
        "\n",
        "q0 = torch.rand(1, 4) #          initial conditions\n",
        "l = 256              #          length\n",
        "tx = 5               #          duration\n",
        "t_n = torch.tensor(np.linspace(0, tx, l)).float()\n",
        "\n",
        "x_anal = torch.tensor(anal_solve_ode(q0[:2], q0[2:], t_n))      #q, qt analytical       \n",
        "qtt_anal = torch.tensor(get_xt_anal(x_anal, t_n))      #qt(same as input), qtt anal\n",
        "traj_x = q2xy(x_anal)\n",
        "E_x = [E(x) for x in x_anal]\n",
        "\n",
        "x_nn = np.zeros((b_len, lr_len, l, 4))\n",
        "qtt_nn = np.zeros((b_len, lr_len, l, 4))\n",
        "traj_nn = np.zeros((b_len, lr_len, l, 4))\n",
        "E_nn = np.zeros((b_len, lr_len, l))\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        qtt_nn[i,j,:,:] = torch.tensor(model[i,j](x_anal.float()).detach().numpy())\n",
        "        x_nn[i,j,:,:] = nn_solve_ode(model[i,j], x_anal[0], t_n)\n",
        "        traj_nn[i,j,:,:] = q2xy(x_nn[i,j])  \n",
        "        E_nn[i,j,:] = [E(x) for x in x_nn[i,j]]\n",
        "\n",
        "losses = np.zeros((b_len, lr_len, 2))\n",
        "tresh = 400\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        losses[i,j,0]=loss(qtt_anal[:,2], qtt_nn[i,j,:,2])\n",
        "        losses[i,j,1]=loss(qtt_anal[:,3], qtt_nn[i,j,:,3])"
      ],
      "metadata": {
        "id": "Hu9NF80IBlwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################# A C C E L E R A T I O N S #########################################\n",
        "fig = plt.figure(figsize=(16,12)) \n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(t_n, qtt_anal[:, 2], 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,0] < tresh: \n",
        "            plt.plot(t_n, qtt_nn[i,j,:,2], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Theta1_tt')\n",
        "plt.title('Theta1_tt, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(t_n, qtt_anal[:, 3], 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,1] < tresh: \n",
        "            plt.plot(t_n, qtt_nn[i,j,:,3], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Theta2_tt')\n",
        "plt.title('Theta2_tt, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SappOVDmB24_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################# P O S I T I O N S ##############################################\n",
        "\n",
        "fig = plt.figure(figsize=(16,12)) \n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(t_n, x_anal[:, 0], 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,0] < tresh: \n",
        "            plt.plot(t_n, x_nn[i,j,:,0], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Theta1_tt')\n",
        "plt.title('Theta1, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(t_n, x_anal[:, 1], 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,1] < tresh: \n",
        "            plt.plot(t_n, x_nn[i,j,:,1], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Theta2_tt')\n",
        "plt.title('Theta2, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WiHQ7Wa4B27X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################# T R A J E C T O R I E S #########################################\n",
        "\n",
        "a, b = 0, l  #shows array[a:b] in plots (l is their normal length)\n",
        "\n",
        "fig = plt.figure(figsize=(16,16)) \n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(traj_x[a:b, 0], traj_x[a:b, 1], 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,0] < tresh: \n",
        "           plt.plot(traj_nn[i,j,a:b, 0], traj_nn[i,j,a:b, 1], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('x(t)')\n",
        "plt.ylabel('y(t)')\n",
        "plt.title('Trajectory y vs x, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(t_n, np.zeros(l), 'black', label='Truth')\n",
        "\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,0] < tresh: \n",
        "           r = ((traj_nn[i,j,a:b, 0]-traj_x[a:b,0])**2 + (traj_nn[i,j,a:b, 1]-traj_x[a:b,1])**2)**0.5\n",
        "           plt.plot(t_n[a:b], r, '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('sqrt dx^2+dy^2')\n",
        "plt.title('Euclidean distance from truth, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "afHNl7Z4B293"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD6nYiHoBVES"
      },
      "outputs": [],
      "source": [
        "############################# E N E R G I E S #########################################\n",
        "\n",
        "fig = plt.figure(figsize=(16,16)) \n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(t_n, E_x, 'black', label='Truth')\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "        if losses[i,j,1] < tresh: \n",
        "            plt.plot(t_n[a:b], E_nn[i,j,a:b], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Energy')\n",
        "plt.title('Energy vs time, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "\n",
        "############################# L O S S E S #########################################\n",
        "ae, be = 0, eps\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "for i in range(b_len):\n",
        "    for j in range(lr_len):\n",
        "            plt.plot(np.arange(1+ae, be+1, 1), loss_list[i,j,ae:be], '-', label='lr %.0e, bs %i' %(lrs[j], batches[i]))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE(truth-pred)')\n",
        "plt.title('Loss vs epochs, %i epochs, N=%i, samples=%i' %(eps, N, samples))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}
